%pip install scikit-lego


import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklego.linear_model import LADRegression
from sklearn.model_selection import train_test_split


df = pd.read_csv("StudentPerformanceFactorsCleaned.csv")
df.head()


df.info()


df.columns





y = df["Exam_Score"]

#60% for training
df_train = df.sample(frac=0.6, random_state=2)

tmp = df.query("~index.isin(@df_train.index)")

#20% for validation
df_validation = tmp.sample(frac=0.5, random_state=3789)

#20% for testing
df_test = tmp.query("~index.isin(@df_validation.index)")

print(f"Training data: {df_train.shape}")
print(f"Validation data: {df_validation.shape}")
print(f"Testing data: {df_test.shape}")





x_train = np.array(df_train['Hours_Studied']).reshape(-1, 1)
y_train = df_train['Exam_Score']
x_validation = np.array(df_validation['Hours_Studied']).reshape(-1, 1)
y_validation = df_validation['Exam_Score']

#linear regression
ls_area_fit = LinearRegression()
ls_area_fit.fit(x_train, y_train)

#pred on training set
pred_train_df = ls_area_fit.predict(x_train)

#pred on validation set
pred_val_df = ls_area_fit.predict(x_validation)





# Step 5: Calculate evaluation metrics for the training set
train_mse = mean_squared_error(y_train, pred_train_df)
train_r2 = r2_score(y_train, pred_train_df)

print(f"Training MSE: {train_mse}")
print(f"Training R²: {train_r2}")

# Step 6: Calculate evaluation metrics for the validation set
validation_mse = mean_squared_error(y_validation, pred_val_df)
validation_r2 = r2_score(y_validation, pred_val_df)

print(f"Validation MSE: {validation_mse}")
print(f"Validation R²: {validation_r2}")






fig = go.Figure()

#plot points
fig.add_trace(
    go.Scatter(x=df_train[['Hours_Studied',],
                y=df_train['Exam_Score'],
                mode='markers',
                name='Actual'
))

#regression line
fig.add_trace(
    go.Scatter(x=df_train['Hours_Studied'],
                y=ls_area_fit.intercept_ + df_train['Hours_Studied'] * ls_area_fit.coef_[0],
                mode='lines',
                name='LS',
                line={'dash': 'solid',
                      'color': 'black'}
))

fig.show()





# Create a DataFrame to compare true vs predicted values for validation data
pred_val_df = pd.DataFrame({
    'true': y_validation,
    'predicted': pred_val_df
})

# Display the comparison
print(pred_val_df.head())


ls_rmse = np.sqrt(mean_squared_error(pred_val_df['true'], pred_val_df['predicted']))
ls_mae = mean_absolute_error(pred_val_df['true'], pred_val_df['predicted'])
ls_mad = np.median(np.abs(pred_val_df['true'] - pred_val_df['predicted']))
ls_corr = np.corrcoef(pred_val_df['true'], pred_val_df['predicted'])[0, 1]
ls_r2 = r2_score(pred_val_df['true'], pred_val_df['predicted'])

print(f"LS RMSE: {ls_rmse}")
print(f"LS MAE: {ls_mae}")
print(f"LS MAD: {ls_mad}")
print(f"LS Correlation: {ls_corr}")
print(f"LS R²: {ls_r2}")








%pip install mlxtend


X = df_train['Hours_Studied'].values.reshape(-1,1)
# scale the predictors
X_std = (X - X.mean()) / X.std()
y = df_train['Exam_Score'].values.reshape(-1,1)


from sklearn.linear_model import  Ridge, Lasso
from sklearn.model_selection import cross_val_score, cross_validate

# use 10-fold cross-validation to select the best lambda (alpha) value for the ridge regression model

# define the alpha values to test
# note that the start/stop values in the first two arguments are the exponents
alphas = np.logspace(-1, 6, 100)

# create an empty list to store the cross-validation scores
ridge_cv_scores = []

# create a for loop to compute the cross-validation score for each alpha value
for alpha in alphas:
    ridge = Ridge(alpha=alpha)
    ridge_cv = cross_validate(estimator=ridge,
                              X=X_std,
                              y=y,
                              cv=10,
                              scoring='neg_root_mean_squared_error')
    ridge_cv_scores.append({'alpha': alpha,
                            'log_alpha': np.log(alpha),
                            'test_mse': -np.mean(ridge_cv['test_score'])})

# convert the cross-validation scores into a data frame
ridge_cv_scores_df = pd.DataFrame(ridge_cv_scores)

# plot the cross-validation scores as a function of alpha
px.line(ridge_cv_scores_df,
        x='log_alpha',
        y='test_mse',
        title='Ridge')


ridge_cv_scores_df


# use 10-fold cross-validation to select the best lambda (alpha) value for the lasso regression model

# define the alpha values to test
# note that the start/stop values in the first two arguments are the exponents
alphas = np.logspace(-1, 4, 100)

# create an empty list to store the cross-validation scores
lasso_cv_scores = []

# create a for loop to compute the cross-validation score for each alpha value
for alpha in alphas:
    lasso = Lasso(alpha=alpha)
    lasso_cv = cross_validate(estimator=lasso,
                              X=X_std,
                              y=y,
                              cv=10,
                              scoring='neg_root_mean_squared_error')
    lasso_cv_scores.append({'alpha': alpha,
                            'log_alpha': np.log(alpha),
                            'test_mse': -np.mean(lasso_cv['test_score'])})

# convert the cross-validation scores into a data frame
lasso_cv_scores_df = pd.DataFrame(lasso_cv_scores)

# plot the cross-validation scores as a function of alpha
px.line(lasso_cv_scores_df,
        x='log_alpha',
        y='test_mse',
        title='Lasso')



# fitting ridge model
ridge_alpha_min = ridge_cv_scores_df.sort_values(by='test_mse').head(1).alpha.values[0]
mse_se_ridge = ridge_cv_scores_df['test_mse'].std() / np.sqrt(10)
mse_min_ridge = ridge_cv_scores_df['test_mse'].min()
ridge_alpha_1se = ridge_cv_scores_df[(ridge_cv_scores_df['test_mse'] <= mse_min_ridge + mse_se_ridge) &
                                     (ridge_cv_scores_df['test_mse'] >= mse_min_ridge - mse_se_ridge)].sort_values(by='alpha', ascending=False).head(1).alpha.values[0]


#fitting lasso model
lasso_alpha_min = lasso_cv_scores_df.sort_values(by='test_mse').head(1).alpha.values[0]
mse_se_lasso = lasso_cv_scores_df['test_mse'].std() / np.sqrt(10)
mse_min_lasso = lasso_cv_scores_df['test_mse'].min()
lasso_alpha_1se = lasso_cv_scores_df[(lasso_cv_scores_df['test_mse'] <= mse_min_lasso + mse_se_lasso) &
                                     (lasso_cv_scores_df['test_mse'] >= mse_min_lasso - mse_se_lasso)].sort_values(by='alpha', ascending=False).head(1).alpha.values[0]



print('Ridge (min): ', ridge_alpha_min)
print('Ridge (1SE): ', ridge_alpha_1se)
print('Lasso (min): ', lasso_alpha_min)
print('Lasso (1SE): ', lasso_alpha_1se)




ridge_min_fit = Ridge(alpha=ridge_alpha_min).fit(X=X_std, y=y)
ridge_1se_fit = Ridge(alpha=ridge_alpha_1se).fit(X=X_std, y=y)

lasso_min_fit = Lasso(alpha=lasso_alpha_min).fit(X=X_std, y=y)
lasso_1se_fit = Lasso(alpha=lasso_alpha_1se).fit(X=X_std, y=y)



